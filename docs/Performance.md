# Performance

I found 5 human experts and asked them to label a video of about 20000 frames. Then, I only used the frames which they totally agree to be certain behavior. You can check the human labels, machine labels, and related codes [here](https://github.com/Wenlab/Auto-Worm-Behavior-Detector/tree/master/performance).

```
Proportion of frames lacking unanimous consensus among human experts: 15.84%
---------------
Accuracy: 91.36%
Error: 8.64%
---------------
Precision of Forward: 95.82%
Recall of Forward: 95.68%
Precision of Reversal: 71.33%
Recall of Reversal: 99.70%
Precision of Turn: 100.00%
Recall of Turn: 44.60%
```
